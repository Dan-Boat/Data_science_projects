{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca770241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import models\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c3c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data \n",
    "train_npz = np.load(\"Audiobooks_data_train.npz\")\n",
    "validation_npz = np.load(\"Audiobooks_data_validation.npz\")\n",
    "test_npz = np.load(\"Audiobooks_data_test.npz\")\n",
    "\n",
    "train_inputs, train_targets = train_npz[\"inputs\"].astype(np.float), train_npz[\"targets\"].astype(np.float)\n",
    "validation_inputs, validation_targets = validation_npz[\"inputs\"].astype(np.float), validation_npz[\"targets\"].astype(np.float)\n",
    "test_inputs, test_targets = test_npz[\"inputs\"].astype(np.float), test_npz[\"targets\"].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e18ff4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3579, 10), (448, 10), (447, 10))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, test_inputs.shape, validation_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9b37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn(hidden_layer_size, input_size, output_size, plot_network=False, activation=\"relu\"):\n",
    "    \n",
    "    #simple structure---complex like 5000 (10 layers) on 100 epochs will give 99% accuracy \n",
    "    model=Sequential()\n",
    "    model.add(Dense(hidden_layer_size, activation=activation)) #1st layer\n",
    "    model.add(Dense(hidden_layer_size, activation=activation))#2nd layer\n",
    "    #model.add(Dense(hidden_layer_size, activation=activation))#3nd layer\n",
    "    model.add(Dense(output_size, activation=\"softmax\")) #output layer (since categorical data transform outputs into probabilities)\n",
    "    \n",
    "    from ann_visualizer.visualize import ann_viz\n",
    "    if plot_network ==True:\n",
    "        ann_viz(model, title=\"Dense Model\")\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model \n",
    "model = build_nn(hidden_layer_size=50, input_size=10, output_size=2, plot_network=False, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a5bac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 0s - loss: 0.6839 - accuracy: 0.5719 - val_loss: 0.6671 - val_accuracy: 0.5951 - 462ms/epoch - 13ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.6660 - accuracy: 0.5862 - val_loss: 0.6611 - val_accuracy: 0.5884 - 64ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.6573 - accuracy: 0.5990 - val_loss: 0.6588 - val_accuracy: 0.6242 - 64ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.6541 - accuracy: 0.6139 - val_loss: 0.6608 - val_accuracy: 0.6040 - 64ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.6483 - accuracy: 0.6099 - val_loss: 0.6582 - val_accuracy: 0.6018 - 65ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.6453 - accuracy: 0.6169 - val_loss: 0.6582 - val_accuracy: 0.5996 - 65ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.6423 - accuracy: 0.6248 - val_loss: 0.6574 - val_accuracy: 0.6353 - 70ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.6390 - accuracy: 0.6262 - val_loss: 0.6599 - val_accuracy: 0.6421 - 64ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.6387 - accuracy: 0.6320 - val_loss: 0.6598 - val_accuracy: 0.6443 - 70ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8b84b66a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting \n",
    "BATCH_SIZE=100\n",
    "max_epochs=100\n",
    "\n",
    "#define early stoping to prevent overfiting of the model\n",
    "# set patience=2 (to be a bit tolerant against random validation loss increase)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "model.fit(train_inputs, train_targets, batch_size=BATCH_SIZE, epochs=max_epochs, callbacks=[early_stopping],\n",
    "         validation_data=(validation_inputs, validation_targets), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e953630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6272\n",
      "Test loss: 0.65. Test accuracy: 62.72\n"
     ]
    }
   ],
   "source": [
    "#evaluate \n",
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n",
    "print(\"Test loss: {0:.2f}. Test accuracy: {1:.2f}\".format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751a3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
